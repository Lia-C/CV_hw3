{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13458f5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ef482389",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c373c338d8f3ed1d6f148e42f6401bf3",
     "grade": false,
     "grade_id": "cell-13f53db58aca8872",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<img align=\"center\" src=\"figures/course.png\" width=\"800\">\n",
    "\n",
    "#                                    16720 (B) Neural Networks for Recognition - Assignment 3\n",
    "\n",
    "     Instructor: Kris Kitani                       TAs: Arka, Jinkun, Rawal, Rohan, Sheng-Yu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc80285",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3e436a26038a5fc987c7bd6d5b256a2d",
     "grade": false,
     "grade_id": "cell-6401c946baf292ff",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Q4 PyTorch (40 points)\n",
    "\n",
    "**Please include all the write up answers below to HW3:PDF. For the questions that need code, you need to include the screenshot of code to PDF submission to get points.**\n",
    "\n",
    "While you were able to derive manual back-propagation rules for sigmoid and fully-connected layers, wouldn't it be nice if someone did that for lots of useful primatives and made it fast and easy to use for general computation?  Meet [automatic differentiation](https://en.wikipedia.org/wiki/Automatic_differentiation). Since we have high-dimensional inputs (images) and low-dimensional outputs (a scalar loss), it turns out **forward mode AD** is very efficient. Popular autodiff packages include [pytorch](https://pytorch.org/) (Facebook), [tensorflow](https://www.tensorflow.org/) (Google), [autograd](https://github.com/HIPS/autograd) (Boston-area academics). Autograd provides its own replacement for numpy operators and is a drop-in replacement for numpy, except you can ask for gradients now. The other two are able to act as shim layers for [cuDNN](https://developer.nvidia.com/cudnn), an implementation of auto-diff made by Nvidia for use on their GPUs. Since GPUs are able to perform large amounts of math much faster than CPUs, this makes the former two packages very popular for researchers who train large networks. Tensorflow asks you to build a computational graph using its API, and then is able to pass data through that graph. PyTorch builds a dynamic graph and allows you to mix autograd functions with normal python code much more smoothly, so it is currently more popular among CMU students. \n",
    "\n",
    "We will use [pytorch](https://pytorch.org/) as a framework. Many computer vision projects use neural networks as a basic building block, so familiarity with one of these frameworks is a good skill to develop. Here, we basically replicate and slightly expand our handwritten character recognition networks, but do it in PyTorch instead of doing it ourselves. Feel free to use any tutorial you like, but we like [the offical one](https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html) or [this tutorial](http://cs231n.stanford.edu/notebooks/pytorch_tutorial.ipynb) (in a jupyter notebook) or [these slides](http://cs231n.stanford.edu/slides/2018/cs231n_2018_lecture08.pdf (starting from number 35).\n",
    "\n",
    "**For this section, you're free to implement these however you like. All of the tasks required here are fairly small and don't require a GPU if you use small networks, including 4.2.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98c1f2a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b2c3c028cd304575a6d8239bcf2f664f",
     "grade": false,
     "grade_id": "cell-5c75db14ea00d1ae",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Q4.1 Train a neural network in PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9223d5f9",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "dca106c5434b6106cc9d60ea4b8267b6",
     "grade": false,
     "grade_id": "cell-6a8302ccaf83c369",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Q4.1.1 (10 Points Code+WriteUp)\n",
    " \n",
    "Re-write and re-train your fully-connected network on NIST36 in PyTorch. Plot training accuracy and loss over time.\n",
    "\n",
    "<font color=\"red\">**Please include your answer to HW3:PDF**</font>\n",
    "\n",
    "<font color=\"red\">**For this question, please also submit screenshot of your code snippets to the write-up**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c8df423",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import scipy.io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "244a4830",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = scipy.io.loadmat('data/nist36_train.mat')\n",
    "valid_data = scipy.io.loadmat('data/nist36_valid.mat')\n",
    "test_data = scipy.io.loadmat('data/nist36_test.mat')\n",
    "\n",
    "train_x, train_y = train_data['train_data'], train_data['train_labels']\n",
    "valid_x, valid_y = valid_data['valid_data'], valid_data['valid_labels']\n",
    "test_x, test_y = test_data['test_data'], test_data['test_labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41877a7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10800, 1024)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "52267dbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10800, 36)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f4b019bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3600, 1024)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e87c39cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1800, 1024)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361ed3fe",
   "metadata": {},
   "source": [
    "Need to convert one-hot labels to multiclass indices, take argmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "123815c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = [2]\n",
    "target = torch.Tensor(target).type(torch.LongTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "875d07d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10800, 36)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "3e03e83a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  0, ..., 35, 35, 35], dtype=int64)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y_multiclass = np.apply_along_axis(np.argmax, 1, train_y)\n",
    "train_y_multiclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "bb34ed74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_y_multiclass = np.apply_over_axes(np.argmax, train_y, 1)\n",
    "# train_y_multiclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1628df03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "7b3bea23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\liail\\AppData\\Local\\Temp\\ipykernel_41088\\2035083360.py:1: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  train_y_multiclass_torch = np.array([torch.Tensor(x).type(torch.LongTensor) for x in train_y_multiclass])\n",
      "C:\\Users\\liail\\AppData\\Local\\Temp\\ipykernel_41088\\2035083360.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  train_y_multiclass_torch = np.array([torch.Tensor(x).type(torch.LongTensor) for x in train_y_multiclass])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([tensor([0]), tensor([0]), tensor([0]), ..., tensor([35]),\n",
       "       tensor([35]), tensor([35])], dtype=object)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_y_multiclass_torch = np.array([torch.Tensor(x).type(torch.LongTensor) for x in train_y_multiclass])\n",
    "# train_y_multiclass_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a85dc41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "559a426b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n   Train the network with two sequential layers: \\n   (1) one layer named \"layer1\" with sigmoid activation\\n   (2) one layer named \"output\" with softmax activation\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " \"\"\"\n",
    "    Train the network with two sequential layers: \n",
    "    (1) one layer named \"layer1\" with sigmoid activation\n",
    "    (2) one layer named \"output\" with softmax activation\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5a12c406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyNetwork(\n",
      "  (layer1): Linear(in_features=1024, out_features=64, bias=True)\n",
      "  (output): Linear(in_features=64, out_features=36, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "\n",
    "# define the network class\n",
    "class MyNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        # call constructor from superclass\n",
    "        super().__init__()\n",
    "        \n",
    "        # define network layers\n",
    "        self.layer1 = nn.Linear(1024, 64)\n",
    "        self.output = nn.Linear(64, 36)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # define forward pass\n",
    "        # x = F.relu(self.fc1(x))\n",
    "        # x = F.relu(self.fc2(x))\n",
    "        # x = torch.sigmoid(self.fc3(x))\n",
    "        x = torch.sigmoid(self.layer1(x.float()))\n",
    "        x = torch.softmax(self.output(x), dim=-1)\n",
    "    # * (Tensor input, int dim, torch.dtype dtype, *, Tensor out)\n",
    "#  * (Tensor input, name dim, *, torch.dtype dtype)\n",
    "\n",
    "        return x\n",
    "\n",
    "# instantiate the model\n",
    "model = MyNetwork()\n",
    "\n",
    "# print model architecture\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "330278af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparams, I just set these arbitrarily\n",
    "learning_rate = 0.01\n",
    "epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aeda021d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim  \n",
    "\n",
    "# create a stochastic gradient descent optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "# create a loss function\n",
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "a452e285",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10800, 1024)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "1ab368fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y_in = train_y_multiclass\n",
    "\n",
    "train = torch.utils.data.TensorDataset(torch.tensor(train_x), torch.tensor(train_y_in))\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size=64, shuffle=False)\n",
    "\n",
    "valid = torch.utils.data.TensorDataset(torch.tensor(valid_x), torch.tensor(valid_y))\n",
    "valid_loader = torch.utils.data.DataLoader(train, batch_size=64, shuffle=False)\n",
    "\n",
    "test = torch.utils.data.TensorDataset(torch.tensor(test_x), torch.tensor(test_y))\n",
    "test_loader = torch.utils.data.DataLoader(train, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "cc526ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_loader = torch.utils.data.DataLoader(\n",
    "#     datasets.MNIST('../data', train=True, download=True,\n",
    "#                     transform=transforms.Compose([\n",
    "#                         transforms.ToTensor(),\n",
    "#                         transforms.Normalize((0.1307,), (0.3081,))\n",
    "#                     ])),\n",
    "#     batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ee9d08c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_loader = torch.utils.data.DataLoader(\n",
    "#     datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
    "#         transforms.ToTensor(),\n",
    "#         transforms.Normalize((0.1307,), (0.3081,))\n",
    "#     ])),\n",
    "#     batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "801ff2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "ef7d22b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=200\n",
    "learning_rate=0.01\n",
    "log_interval=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "3a2b64ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputshape torch.Size([64, 36])\n",
      "targetshape torch.Size([64])\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "invalid index of a 0-dim tensor. Use `tensor.item()` in Python or `tensor.item<T>()` in C++ to convert a 0-dim tensor to a number",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [126], line 21\u001b[0m\n\u001b[0;32m     17\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[0;32m     18\u001b[0m \u001b[39mif\u001b[39;00m batch_idx \u001b[39m%\u001b[39m log_interval \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m     19\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mTrain Epoch: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m [\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m (\u001b[39m\u001b[39m{:.0f}\u001b[39;00m\u001b[39m%\u001b[39m\u001b[39m)]\u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39mLoss: \u001b[39m\u001b[39m{:.6f}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m     20\u001b[0m             epoch, batch_idx \u001b[39m*\u001b[39m \u001b[39mlen\u001b[39m(data), \u001b[39mlen\u001b[39m(train_loader\u001b[39m.\u001b[39mdataset),\n\u001b[1;32m---> 21\u001b[0m                    \u001b[39m100.\u001b[39m \u001b[39m*\u001b[39m batch_idx \u001b[39m/\u001b[39m \u001b[39mlen\u001b[39m(train_loader), loss\u001b[39m.\u001b[39;49mdata[\u001b[39m0\u001b[39;49m]))\n",
      "\u001b[1;31mIndexError\u001b[0m: invalid index of a 0-dim tensor. Use `tensor.item()` in Python or `tensor.item<T>()` in C++ to convert a 0-dim tensor to a number"
     ]
    }
   ],
   "source": [
    "# run the main training loop\n",
    "for epoch in range(epochs):\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "\n",
    "        # Variable may be deprecated\n",
    "        data, target = Variable(data), Variable(target)\n",
    "\n",
    "        # resize data from (batch_size, 1, 28, 28) to (batch_size, 28*28)\n",
    "        data = data.view(-1, 32*32)\n",
    "        optimizer.zero_grad()\n",
    "        net_out = model(data)\n",
    "\n",
    "        print(\"outputshape\", net_out.shape)\n",
    "        print(\"targetshape\", target.shape)\n",
    "        loss = criterion(net_out, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                    epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                           100. * batch_idx / len(train_loader), loss.data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfeebe31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run a test loop\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "for data, target in test_loader:\n",
    "    data, target = Variable(data, volatile=True), Variable(target)\n",
    "    data = data.view(-1, 28 * 28)\n",
    "    net_out = net(data)\n",
    "    # sum up batch loss\n",
    "    test_loss += criterion(net_out, target).data[0]\n",
    "    pred = net_out.data.max(1)[1]  # get the index of the max log-probability\n",
    "    correct += pred.eq(target.data).sum()\n",
    "\n",
    "test_loss /= len(test_loader.dataset)\n",
    "print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "    test_loss, correct, len(test_loader.dataset),\n",
    "    100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df29c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "max_iters = 50\n",
    "# pick a batch size, learning rate\n",
    "batch_size = None\n",
    "learning_rate = None\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "hidden_size = 64\n",
    "\n",
    "batches = get_random_batches(train_x,train_y,batch_size)\n",
    "batch_num = len(batches)\n",
    "\n",
    "params = {}\n",
    "\n",
    "# initialize layers (named \"layer1\" and \"output\") here\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "\n",
    "# with default settings, you should get loss < 150 and accuracy > 80%\n",
    "for itr in range(max_iters):\n",
    "    total_loss = 0\n",
    "    total_acc = 0\n",
    "    for xb,yb in batches:\n",
    "        \n",
    "        # training loop can be exactly the same as q2!\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "    if itr % 2 == 0:\n",
    "        print(\"itr: {:02d} \\t loss: {:.2f} \\t acc : {:.2f}\".format(itr,total_loss,total_acc))\n",
    "\n",
    "# run on validation set and report accuracy! should be above 70%\n",
    "valid_acc = None\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "print('Validation accuracy: ',valid_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef1c250",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "49f03f996c9d1ac506ff3223525222ef",
     "grade": true,
     "grade_id": "cell-88a606e8a400dc8b",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# a single hidden layer with 64 hidden units, and train for at least 30 epochs.\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08d0f13",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ff5a75b2296597c74716b759f4a5c788",
     "grade": false,
     "grade_id": "cell-532aaec5d587259a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Q4.1.2 (3 Points Code+WriteUp)\n",
    " \n",
    "Train a convolutional neural network with PyTorch on MNIST. Plot training accuracy and loss over time.\n",
    "\n",
    "<font color=\"red\">**Please include your answer to HW3:PDF**</font>\n",
    "\n",
    "<font color=\"red\">**For this question, please also submit screenshot of your code snippets to the write-up**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02227711",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "87ddc39f0302f43e3adceeb2a4f9d7c2",
     "grade": true,
     "grade_id": "cell-db5a77f9ccaf8fd3",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Conv2d\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d861662",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f4a0f0018af8460a26e4cba54a79a3df",
     "grade": false,
     "grade_id": "cell-224cbb8be1a16286",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Q4.1.3 (2 Points Code+WriteUp)\n",
    " \n",
    "Train a convolutional neural network with PyTorch on the included NIST36 dataset. Plot training accuracy and loss over time.\n",
    "\n",
    "<font color=\"red\">**Please include your answer to HW3:PDF**</font>\n",
    "\n",
    "<font color=\"red\">**For this question, please also submit screenshot of your code snippets to the write-up**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20761659",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "183705ab99712d3922251f57b8032ad8",
     "grade": true,
     "grade_id": "cell-87cfe11794cd5054",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e7e34e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1e5001cc88df569d4944ce40253badb0",
     "grade": false,
     "grade_id": "cell-b4fe717706236784",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Q4.1.4 (15 Points Code+WriteUp)\n",
    " \n",
    "Train a convolutional neural network with PyTorch on the EMNIST Balanced dataset  (available in *torchvision.datasets*, use *balanced* split) and evaluate it on the findLetters bounded boxes from the images folder. Find the accuracy on these bounded boxes.\n",
    "\n",
    "<font color=\"red\">**Please include your answer to HW3:PDF**</font>\n",
    "\n",
    "<font color=\"red\">**For this question, please also submit screenshot of your code snippets to the write-up**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e00a6a4",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6557e17efc6bc3051d20ab968160e1ac",
     "grade": true,
     "grade_id": "cell-96954b5ffa647538",
     "locked": false,
     "points": 15,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3301e587",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2493cb7d8e466b09e2b9c88f402587da",
     "grade": false,
     "grade_id": "cell-d3bb203777b72e08",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Q4.2 Fine Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a65f628",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9ade32f8d5ea05cbc36da0a1e4dd6f58",
     "grade": false,
     "grade_id": "cell-d067bc4110bebd56",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Q4.2.1 (10 Points Code+WriteUp)\n",
    " \n",
    "Fine-tune a single layer classifier using pytorch on the [flowers 17](http://www.robots.ox.ac.uk/~vgg/data/flowers/17/index.html) (or [flowers 102](http://www.robots.ox.ac.uk/~vgg/data/flowers/102/index.html)!) dataset using [squeezenet1\\_1](https://pytorch.org/docs/stable/torchvision/models.html), as well as an architecture you've designed yourself (*3 conv layers, followed 2 fc layers, it's standard [slide 6](http://cs231n.stanford.edu/slides/2018/cs231n_2018_lecture09.pdf)*) and trained from scratch. How do they compare? \n",
    "    \n",
    "We include a script in `scripts/` to fetch the flowers dataset and extract it in a way that [PyTorch ImageFolder](https://pytorch.org/docs/stable/torchvision/datasets.html#imagefolder) can consume it, see [an example](https://pytorch.org/tutorials/beginner/data_loading_tutorial.html#afterword-torchvision), from **data/oxford-flowers17**. You should look at how SqueezeNet is [defined](https://github.com/pytorch/vision/blob/master/torchvision/models/squeezenet.py), and just replace the classifier layer. There exists a pretty good example for [fine-tuning](https://gist.github.com/jcjohnson/6e41e8512c17eae5da50aebef3378a4c) in PyTorch.\n",
    "\n",
    "<font color=\"red\">**Please include your answer to HW3:PDF**</font>\n",
    "\n",
    "<font color=\"red\">**For this question, please also submit screenshot of your code snippets to the write-up**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc3b8e0",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8fa209b8e469cc16419354efdb6a1a5c",
     "grade": true,
     "grade_id": "cell-a35068c20e20519b",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aba22c3",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "01e6491f5f8677c09b27fef6ed328628",
     "grade": true,
     "grade_id": "cell-a94d41f5ea3dcc20",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('cv_hw')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "3baf386052658501891e8c70ba6a2b62e900282515b79869d0a53bf79ee7c064"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
